# ai-lens-helper

> ì¥ì†Œë³„ ì „ì‹œí’ˆ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ê³ , ì¶”ë¡  ì‹œ **ì¥ì†Œëª… + ì´ë¯¸ì§€** ì…ë ¥ìœ¼ë¡œ í•´ë‹¹ ì „ì‹œí’ˆ(í˜¹ì€ â€œì¬ì´¬ì˜ ê¶Œìœ â€)ì„ íŒë³„í•˜ëŠ” ê²½ëŸ‰ CLI/SDK.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥ (Features)

- **CLI í•™ìŠµ íŒŒì´í”„ë¼ì¸**: í´ë”/ë©”íƒ€ì—ì„œ ìë™ ë¡œë”© â†’ ì „ì²˜ë¦¬ â†’ ì¦ê°• â†’ í•™ìŠµ/ê²€ì¦ â†’ ì²´í¬í¬ì¸íŠ¸/ë¦¬í¬íŠ¸ ì €ì¥
- **ì¶”ë¡  API/CLI**: `place + image` ì…ë ¥ â†’ ì „ì‹œí’ˆ í›„ë³´/ì‹ ë¢°ë„ ë°˜í™˜, ì„ê³„ì¹˜ ë¯¸ë‹¬ ì‹œ â€œìƒˆë¡œ ì´¬ì˜ ê¶Œê³ â€
- **ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ + ë¶„ë¥˜ í•˜ì´ë¸Œë¦¬ë“œ**: ë¼ë²¨ ì¶”ë¡ ì˜ ê²¬ê³ ì„±ê³¼ OOD(ì „ì‹œí’ˆ ì™¸ë¬¼ì²´) ê±°ì ˆ(Reject) ì„±ëŠ¥ ê°•í™”
- **ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬**: ì´ë¯¸ì§€ ìˆ˜/í•´ìƒë„/ì¤‘ë³µ ê²€ì‚¬, í´ë˜ìŠ¤ ë¶ˆê· í˜• ê²½ê³ 
- **ëª¨ë¸/ë°ì´í„° ë²„ì €ë‹**: `semver` + ë©”íƒ€(JSON) ê¸°ë¡, ì¬í˜„ ê°€ëŠ¥í•œ ëŸ°(Seed ê³ ì •, í™˜ê²½ ìŠ¤ëƒ…ìƒ·)
- **ê²½ëŸ‰ ë°°í¬**: ONNX/TorchScript ë‚´ë³´ë‚´ê¸°, CPUÂ·Edge ìš°ì„  ì„¤ê³„

---

## ğŸ“¦ ì„¤ì¹˜ (Installation)

```bash
pip install ai-lens-helper
# or (ê°œë°œ)
pip install -e .[dev]
```

---

## ğŸ—‚ï¸ ë°ì´í„° ë””ë ‰í„°ë¦¬ ê·œì•½ (Dataset Layout)

```
./data/
  A/
    ã„±/
      img_001.jpg
      ... (ìµœì†Œ 10ì¥ ê¶Œì¥)
    ã„´/
    ...
  B/
  C/
```

- í´ë”ëª…: **ì¥ì†Œ/ì „ì‹œí’ˆ**
- ê° ì „ì‹œí’ˆ ìµœì†Œ 10ì¥, ë‹¤ì–‘í•œ ê°ë„/ê±°ë¦¬/ì¡°ëª… í¬í•¨ ê¶Œì¥
- (ì„ íƒ) `metadata.json`: ì´¬ì˜ê¸°ê¸°/ë‚ ì§œ/ë¼ë²¨ ì„¤ëª… ë“±

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Quickstart)

### 0) GUI ì• í”Œë¦¬ì¼€ì´ì…˜ (ì¶”ì²œ!)

**YOLO+CLIP ê¸°ë°˜ ì „ì‹œí’ˆ ì¸ì‹ ì‹œìŠ¤í…œì„ GUIì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•˜ì„¸ìš”!**

```bash
# GUI ì‹¤í–‰
python3 gui_app.py
# ë˜ëŠ”
./run_gui.sh
```

**ê¸°ëŠ¥:**
- ğŸ“š **Tab 1: ì¸ë±ìŠ¤ ë¹Œë“œ (í•™ìŠµ)** - ìˆ˜ì§‘í•œ ì´ë¯¸ì§€ë¡œ YOLO+CLIP ì¸ë±ìŠ¤ ìƒì„±
- ğŸ” **Tab 2: Inference (í…ŒìŠ¤íŠ¸)** - ì‹¤ì‹œê°„ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ë° ê²°ê³¼ í™•ì¸
- ğŸ¤– **Tab 3: OpenAI Vision** - OpenAI GPT-4 Vision APIë¡œ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸ (í•™ìŠµ ë¶ˆí•„ìš”)

**ìì„¸í•œ ì‚¬ìš©ë²•:**
- [GUI_USAGE.md](./GUI_USAGE.md) - GUI ì „ì²´ ì‚¬ìš©ë²•
- [OPENAI_VISION_GUIDE.md](./OPENAI_VISION_GUIDE.md) - OpenAI Vision API ê°€ì´ë“œ

### 1) CLIë¡œ YOLO+CLIP ì¸ë±ìŠ¤ ë¹Œë“œ

**YOLO+CLIP ëª¨ë¸ ì‚¬ìš© (ê¶Œì¥):**

```bash
# ì¸ë±ìŠ¤ ë¹Œë“œ
ai-lens build-clip-index \
  --data-root ./data \
  --place "ê²½ë³µê¶" \
  --save ./indexes/ê²½ë³µê¶_clip \
  --device cpu \
  --yolo-model yolov8n.pt \
  --clip-model ViT-B-16
```

ì˜µì…˜ ìš”ì•½:
- `--data-root`: ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (data/{place}/{item}/*.jpg êµ¬ì¡°)
- `--place`: ì¥ì†Œëª… (ì˜ˆ: "ê²½ë³µê¶", "êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€")
- `--save`: ì €ì¥ ê²½ë¡œ (í™•ì¥ì ì œì™¸, .json/.faiss ìë™ ìƒì„±)
- `--device`: `cpu` ë˜ëŠ” `cuda`
- `--yolo-model`: YOLO ëª¨ë¸ í¬ê¸° (`yolov8n.pt`~`yolov8l.pt`)
- `--clip-model`: CLIP ëª¨ë¸ (`ViT-B-16` ê¶Œì¥)

**ê¸°ì¡´ Color-based ëª¨ë¸ (í”„ë¡œí† íƒ€ì…):**

```bash
ai-lens build-index \
  --model model.json \
  --data-root ./data \
  --place A \
  --save ./A.index
```

### 2) Inference (ë‹¨ì¼ ì´ë¯¸ì§€)

```bash
ai-lens infer \
  --model ./indexes/ê²½ë³µê¶_clip.json \
  --place "ê²½ë³µê¶" \
  --image ./sample.jpg \
  --reject-threshold 0.7 \
  --topk 5
```

**ì°¸ê³ :** ëª¨ë¸ íƒ€ì…(YOLO+CLIP vs Color-based)ì€ ìë™ ê°ì§€ë©ë‹ˆë‹¤.

ì¶œë ¥ ì˜ˆì‹œ(JSON):

```json
{
  "place": "A",
  "predictions": [
    { "item": "ã„±", "score": 0.93 },
    { "item": "ã„´", "score": 0.71 },
    { "item": "ã…", "score": 0.4 }
  ],
  "decision": "accept",
  "selected_item": "ã„±",
  "confidence": 0.93
}
```

ì„ê³„ì¹˜ ë¯¸ë‹¬ ì‹œ:

```json
{
  "place": "A",
  "predictions": [
    { "item": "ã„±", "score": 0.55 },
    { "item": "ã„´", "score": 0.5 }
  ],
  "decision": "recollect",
  "message": "ì „ì‹œí’ˆì´ ì•„ë‹Œ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ˆì /êµ¬ë„/ì¡°ëª… ê°œì„  í›„ ì¬ì´¬ì˜ í•´ì£¼ì„¸ìš”.",
  "hints": [
    "ì‘í’ˆì´ í”„ë ˆì„ ì¤‘ì•™ì— ì˜¤ë„ë¡",
    "ë°˜ì‚¬/ê¸€ë ˆì–´ ì¤„ì´ê¸°",
    "ë” ê°€ê¹Œì´ ì´¬ì˜"
  ]
}
```

### 3) ë°°ì¹˜ ì¶”ë¡ (í´ë”)

```bash
ai-lens infer-batch \
  --model ./runs/2025-10-16/best.ckpt \
  --place A \
  --input-dir ./captures/A \
  --output ./captures/A_results.jsonl
```

---

## ğŸ”§ Python SDK

```python
from ai_lens_helper import Lens

lens = Lens(model_path="./runs/2025-10-16/best.onnx")
result = lens.infer(place="A", image_path="./sample.jpg", reject_threshold=0.62)
print(result.decision, result.selected_item, result.confidence)
```

---

## âš™ï¸ êµ¬ì„±(ì„¤ì •) íŒŒì¼ ì˜ˆì‹œ

```yaml
# configs/default.yaml
seed: 42
img_size: 224
backbone: vit_b16
optimizer: adamw
lr: 3e-4
weight_decay: 0.05
scheduler: cosine
loss: arcface
embedding_dim: 512
augment:
  random_resized_crop: true
  color_jitter: 0.2
  horizontal_flip: true
  gaussian_blur: true
reject:
  threshold: 0.62
  min_top1_margin: 0.12
export:
  onnx: true
  opset: 17
```

---

## ğŸ§ª í‰ê°€ (Evaluation)

- **Split**: Stratified K-fold(5x) + ì¥ì†Œë³„ Holdout(ì‹ ê·œ ë°©ë¬¸ ì¼ë°˜í™” ì²´í¬)
- **ì§€í‘œ**: Top-1/Top-3 Acc, mAP, AUROC(Reject), EER, FPR@TPR
- **ë¦¬í¬íŠ¸**: `runs/*/report.html` (í˜¼ë™í–‰ë ¬, PR/ROC, ì„ë² ë”© t-SNE/UMAP)

---

## ğŸ› ï¸ ì—ëŸ¬ ì½”ë“œ

| ì½”ë“œ | ì˜ë¯¸                   | í•´ê²°                              |
| ---- | ---------------------- | --------------------------------- |
| E100 | ë°ì´í„° ë ˆì´ì•„ì›ƒ ë¶ˆì¼ì¹˜ | `data/place/item/*.jpg` êµ¬ì¡° ì ê²€ |
| E110 | í´ë˜ìŠ¤ë‹¹ ì´ë¯¸ì§€ ë¶€ì¡±   | ê° ì „ì‹œí’ˆ â‰¥10ì¥ ìˆ˜ì§‘              |
| E200 | ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨         | ê²½ë¡œ/ê¶Œí•œ/ë²„ì „ í™•ì¸               |
| E310 | Reject ì„ê³„ì¹˜ ë¯¸ì„¤ì •   | `--reject-threshold` ì§€ì •         |

---

## ğŸ”­ ë¡œë“œë§µ

- ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤( CoreML / NNAPI ) ë‚´ë³´ë‚´ê¸°
- í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë§ˆì´ë‹ ìë™í™”
- ë©€í‹°ì¥ì†Œ ë™ì‹œ ì¶”ë¡  + ìºì‹±
- ì˜¨-ì‚¬ì´íŠ¸ ì¦ë¶„í•™ìŠµ(ì†ŒëŸ‰ ì‹ ìƒ˜í”Œë¡œ ì—…ë°ì´íŠ¸)

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

#### AI ì´ë¯¸ì§€ ìˆ˜ì§‘ CLI

ai-lens collect-data museum_spec.json --num-images 20 --output-root ./data --engine naver --headless --report crawl_report.json

ai-lens collect-data museum_spec.json \
 --num-images 20 \
 --output-root ./data \
 --engine naver \
 --headless \
 --report crawl_report.json
